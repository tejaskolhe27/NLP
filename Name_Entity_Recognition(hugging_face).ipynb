{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d8fe8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82e16b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0a11cd40894bd6a29c7617d08180b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e7124a539e64583b6eac456a71b29b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4706ff83072f48729fad0d552e5ef336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf2645163ee4642b5019829176373e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#prebuild model by hugging face for Name Entity Recognition\n",
    "ner = pipeline('token-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22b0b612",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Mark Zukerberg will meet Indian Prime Minister Narendra Modi in \n",
    "New York, USA on Mondya 4th  June 2023 at 3 pm\n",
    "for $3 Trillion deal\"\"\"\n",
    "result = ner(text)\n",
    "df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67744920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>score</th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-PER</td>\n",
       "      <td>0.999697</td>\n",
       "      <td>1</td>\n",
       "      <td>Mark</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I-PER</td>\n",
       "      <td>0.999222</td>\n",
       "      <td>2</td>\n",
       "      <td>Z</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I-PER</td>\n",
       "      <td>0.980285</td>\n",
       "      <td>3</td>\n",
       "      <td>##uke</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I-PER</td>\n",
       "      <td>0.776790</td>\n",
       "      <td>4</td>\n",
       "      <td>##rber</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I-PER</td>\n",
       "      <td>0.991929</td>\n",
       "      <td>5</td>\n",
       "      <td>##g</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I-MISC</td>\n",
       "      <td>0.998960</td>\n",
       "      <td>8</td>\n",
       "      <td>Indian</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I-PER</td>\n",
       "      <td>0.999572</td>\n",
       "      <td>11</td>\n",
       "      <td>Na</td>\n",
       "      <td>47</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I-PER</td>\n",
       "      <td>0.992167</td>\n",
       "      <td>12</td>\n",
       "      <td>##ren</td>\n",
       "      <td>49</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I-PER</td>\n",
       "      <td>0.998946</td>\n",
       "      <td>13</td>\n",
       "      <td>##dra</td>\n",
       "      <td>52</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I-PER</td>\n",
       "      <td>0.998961</td>\n",
       "      <td>14</td>\n",
       "      <td>Mo</td>\n",
       "      <td>56</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I-PER</td>\n",
       "      <td>0.990233</td>\n",
       "      <td>15</td>\n",
       "      <td>##di</td>\n",
       "      <td>58</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I-LOC</td>\n",
       "      <td>0.999644</td>\n",
       "      <td>17</td>\n",
       "      <td>New</td>\n",
       "      <td>65</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I-LOC</td>\n",
       "      <td>0.999625</td>\n",
       "      <td>18</td>\n",
       "      <td>York</td>\n",
       "      <td>69</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I-LOC</td>\n",
       "      <td>0.999569</td>\n",
       "      <td>20</td>\n",
       "      <td>USA</td>\n",
       "      <td>75</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I-MISC</td>\n",
       "      <td>0.529408</td>\n",
       "      <td>22</td>\n",
       "      <td>Mon</td>\n",
       "      <td>82</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    entity     score  index    word  start  end\n",
       "0    I-PER  0.999697      1    Mark      0    4\n",
       "1    I-PER  0.999222      2       Z      5    6\n",
       "2    I-PER  0.980285      3   ##uke      6    9\n",
       "3    I-PER  0.776790      4  ##rber      9   13\n",
       "4    I-PER  0.991929      5     ##g     13   14\n",
       "5   I-MISC  0.998960      8  Indian     25   31\n",
       "6    I-PER  0.999572     11      Na     47   49\n",
       "7    I-PER  0.992167     12   ##ren     49   52\n",
       "8    I-PER  0.998946     13   ##dra     52   55\n",
       "9    I-PER  0.998961     14      Mo     56   58\n",
       "10   I-PER  0.990233     15    ##di     58   60\n",
       "11   I-LOC  0.999644     17     New     65   68\n",
       "12   I-LOC  0.999625     18    York     69   73\n",
       "13   I-LOC  0.999569     20     USA     75   78\n",
       "14  I-MISC  0.529408     22     Mon     82   85"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1966879a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
